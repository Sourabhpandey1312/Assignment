{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the dataset\n",
    "df = pd.read_csv('/Users/sourabhpandey/Desktop/ML_Assignment/data/Rotten_Tomatoes_Movies3.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary statistics of the datset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['audience_rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('critics_consensus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/sourabhpandey/Desktop/ML_Assignment/data/Rotten_Tomatoes_Movies3.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Set the dark_background style\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Define the numerical columns to check for outliers\n",
    "numerical_columns = ['runtime_in_minutes', 'tomatometer_rating', 'audience_rating', 'tomatometer_count']\n",
    "\n",
    "# Create box plots before removing outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.suptitle('Box Plots Before Removing Outliers', fontsize=16)\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    df.boxplot(column=[column])\n",
    "    plt.title(f'{column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate z-scores for numerical columns\n",
    "z_scores = pd.DataFrame()\n",
    "for column in numerical_columns:\n",
    "    z_scores[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "# Set a z-score threshold to identify outliers\n",
    "z_score_threshold = 2\n",
    "\n",
    "# Identify outliers based on z-scores\n",
    "outliers = z_scores[(z_scores.abs() > z_score_threshold).any(axis=1)]\n",
    "\n",
    "# Display the number of rows with outliers before removal\n",
    "print(\"Number of rows with outliers before removal:\", len(outliers))\n",
    "\n",
    "# Remove outliers and create a new DataFrame\n",
    "df_cleaned = df[~((z_scores.abs() > z_score_threshold).any(axis=1))]\n",
    "\n",
    "# Create box plots after removing outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.suptitle('Box Plots After Removing Outliers', fontsize=16)\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    df_cleaned.boxplot(column=[column])\n",
    "    plt.title(f'{column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the number of rows after removing outliers\n",
    "print(\"Number of rows after removing outliers:\", len(df_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Audience Rating Distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['audience_rating'], kde=True, color='blue')\n",
    "plt.title('Audience Rating Distribution')\n",
    "plt.xlabel('Audience Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Rating vs Genre (Boxplot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='genre', y='audience_rating', data=df)\n",
    "plt.title('Audience Rating vs Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Runtime vs Audience Rating (Scatter Plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='runtime_in_minutes', y='audience_rating', data=df, color='green')\n",
    "plt.title('Runtime vs Audience Rating')\n",
    "plt.xlabel('Runtime in Minutes')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Tomatometer Rating vs Audience Rating (Scatter Plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='tomatometer_rating', y='audience_rating', data=df, color='red')\n",
    "plt.title('Tomatometer Rating vs Audience Rating')\n",
    "plt.xlabel('Tomatometer Rating')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Audience Rating vs Tomatometer Rating (Scatter Plot & Correlation)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='tomatometer_rating', y='audience_rating', data=df, color='purple')\n",
    "plt.title('Audience Rating vs Tomatometer Rating')\n",
    "plt.xlabel('Tomatometer Rating')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.show()\n",
    "\n",
    "# Correlation between Tomatometer Rating and Audience Rating\n",
    "correlation = df['tomatometer_rating'].corr(df['audience_rating'])\n",
    "print(f'Correlation between Tomatometer Rating and Audience Rating: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Audience Rating vs Studio (Boxplot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='studio_name', y='audience_rating', data=df)\n",
    "plt.title('Audience Rating vs Studio')\n",
    "plt.xlabel('Studio')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Print average audience rating by studio\n",
    "studio_rating = df.groupby('studio_name')['audience_rating'].mean()\n",
    "print(\"Average Audience Rating by Studio:\")\n",
    "print(studio_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Audience Rating vs Runtime (Scatter Plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='runtime_in_minutes', y='audience_rating', data=df, color='orange')\n",
    "plt.title('Audience Rating vs Runtime')\n",
    "plt.xlabel('Runtime in Minutes')\n",
    "plt.ylabel('Audience Rating')\n",
    "plt.show()\n",
    "\n",
    "# Print correlation between runtime and audience rating\n",
    "runtime_correlation = df['runtime_in_minutes'].corr(df['audience_rating'])\n",
    "print(f'Correlation between Runtime and Audience Rating: {runtime_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation Matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "\n",
    "# Selecting only numeric columns for correlation\n",
    "numeric_columns = df.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 2. Pairplot\n",
    "# Print selected numeric columns\n",
    "print(\"\\nPairplot Variables:\")\n",
    "print(numeric_columns.columns.tolist())\n",
    "\n",
    "# Display pairplot for numeric columns\n",
    "sns.pairplot(numeric_columns, diag_kind='kde', kind='scatter', palette='husl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Assign the target variable (y) and independent variables (X)\n",
    "target_column = 'audience_rating'  # Set the target column for prediction\n",
    "X = df.drop(columns=[target_column])  # Independent variables\n",
    "y = df[target_column]  # Target variable\n",
    "\n",
    "# Print the shapes of X and y to verify\n",
    "print(\"Shape of independent variables (X):\", X.shape)\n",
    "print(\"Shape of target variable (y):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[60], line 5\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m numerical_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the StandardScaler\u001b[39;00m\n",
      "\u001b[0;32m----> 5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fit and transform the numerical columns\u001b[39;00m\n",
      "\u001b[1;32m      8\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X[numerical_columns])\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns\n",
    "numerical_columns = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "X_scaled = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Create a DataFrame for the scaled features\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numerical_columns)\n",
    "\n",
    "# Drop the original numerical columns from X and concatenate the scaled columns\n",
    "X_final_scaled = pd.concat([X.drop(columns=numerical_columns), X_scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure X contains only numeric columns\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Handle missing and infinite values\n",
    "X_numeric = X_numeric.replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "X_numeric = X_numeric.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# Add a constant column for statsmodels VIF calculation\n",
    "X_numeric = sm.add_constant(X_numeric)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Print the VIF values\n",
    "print(\"Variance Inflation Factor (VIF) for each feature:\")\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "X_categorical_encoded = ohe.fit_transform(X[categorical_columns])\n",
    "\n",
    "# Retrieve feature names for the encoded columns\n",
    "feature_names = []\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    categories = ohe.categories_[i]\n",
    "    for category in categories:\n",
    "        feature_names.append(f\"{col}_{category}\")\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "X_categorical_encoded_df = pd.DataFrame(X_categorical_encoded, columns=feature_names)\n",
    "# Create a DataFrame for the encoded features\n",
    "X_categorical_encoded_df = pd.DataFrame(X_categorical_encoded, columns=feature_names)\n",
    "X_categorical_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Separate the independent features (X) and the target variable (y)\n",
    "X = df.drop(columns=['audience_rating'])  # Drop the target variable from the feature set\n",
    "y = df['audience_rating']\n",
    "\n",
    "# Identify the numerical columns in X (excluding the target variable)\n",
    "numerical_columns = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Instantiate MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the numerical columns in X\n",
    "X_numeric_scaled = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Create a DataFrame for the scaled numerical features\n",
    "X_numeric_scaled_df = pd.DataFrame(X_numeric_scaled, columns=numerical_columns)\n",
    "\n",
    "# Display the scaled numerical feature DataFrame\n",
    "print(X_numeric_scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the scaled columns and onehotencoded columns\n",
    "X_final = pd.concat([X_numeric_scaled_df, X_categorical_encoded_df, ], axis=1)\n",
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Instantiate MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape 'Rating' to a 2D array for MinMaxScaler\n",
    "y_scaled = scaler.fit_transform(df['audience_rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert 'y_scaled' back to a DataFrame\n",
    "y = pd.DataFrame(y_scaled, columns=['audience_rating'])\n",
    "\n",
    "# Print the scaled target variable DataFrame\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "#### Baseline Model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Create a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "y_pred_train = lr_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Test Mean Squared Error : {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "\n",
    "print(f\"Train Mean Squared Error : {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot for the test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.5, color='blue', label='Actual vs Predicted (Test Data)')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "y_pred_train = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Random Forest Regressor Model Evaluation:\")\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model: Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = gb_model.predict(X_test)\n",
    "y_pred_train = gb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Model Evaluation:\")\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared (R^2) Score: {r2_test}\")\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared (R^2) Score: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
